# TWO-NN: Intrinsic dimension estimator by a minimal neighborhood information.
#
# Author: Maria d'Errico <mariaderr@gmail.com>
#
# Licence: BSD 3 clause

from __future__ import annotations
import warnings
import numpy as np
import heapq
from sklearn.base import BaseEstimator
from sklearn.utils.validation import check_array
from sklearn.neighbors import NearestNeighbors
from math import log

VALID_METRIC = ['precomputed', 'euclidean', 'cosine']


def _twoNearestNeighbors(distances, blockAn=True, block_ratio=20, frac=1):
    """Main function for the TWO-NN estimator.
    Parameters
    ----------

    distances: array [n_samples, k_max]
        Distances to the k_max neighbors of each points.

    blockAn : bool, default=True
        If blockAn is True the algorithm perform a block analysis that allows discriminating the relevant dimensions
        as a function of the block size. This allows to study the stability of the estimation with respect to
        changes in the neighborhood size, which is crucial for ID estimations when the data lie on a manifold perturbed
        by a high-dimensional noise.
    block_ratio : int, default=20
        Set the minimum size of the blocks as `n_samples/block_ratio`. If ``blockAn=False``, block_ratio is ignored.
    frac : float, default=1
        Define the fraction of points in the data set used for ID calculation. By default the full data set is used.
    """

    N = len(distances)
    log_nu = []
    d_mle = 0.
    for i in range(0, N):
        log_nu_i = log(distances[i][2]) - log(distances[i][1])
        log_nu.append(log_nu_i)
        d_mle = d_mle + log_nu_i
    # Intrinsic dimension estimated with MLE variant of TWO-NN
    id_mle = int(round(N / d_mle))

    # Perform linear fit -log[1-F(nu)]=d*log(nu), where F(nu)=i/N, with intercept=0
    x = log_nu
    if frac < 1:
        x = []
        heapq.heapify(log_nu)
        for _ in range(int(round(len(log_nu) * frac))):
            x.append(heapq.heappop(log_nu))
    else:
        x = sorted(log_nu)

    # y = [-log(1.-(i+1)/N) for i in range(len(x))]
    y = [-log(1. - (i) / N) for i in range(len(x))]
    # Fit the model y = a * x using np.linalg.lstsq
    a, _, _, _ = np.linalg.lstsq(np.array(x)[:, np.newaxis], np.array(y), rcond=None)
    id = a[0]

    return id, x, y


class TwoNearestNeighbors(BaseEstimator):
    """Class definition for TWO-NN: Intrinsic dimension estimator by a minimal neighborhood information.
    The TWO-NN estimator uses only the distances to the first two nearest neighbors of each point.
    Parameters
    ----------
    metric : string, or callable
        The distance metric to use.
        If metric is a string, it must be one of the options allowed by
        scipy.spatial.distance.pdist for its metric parameter, or a metric listed in
        :obj:`VALID_METRIC = [precomputed, euclidean,cosine]`. If metric is ``precomputed``, X is assumed to
        be a distance matrix. Alternatively, if metric is a callable function, it is
        called on each pair of instances (rows) and the resulting value recorded. The
        callable should take two arrays from X as input and return a value indicating
        the distance between them. Default is ``euclidean``.
    blockAn : bool, default=True
        If blockAn is True the algorithm perform a block analysis that allows discriminating the relevant dimensions
        as a function of the block size. This allows to study the stability of the estimation with respect to
        changes in the neighborhood size, which is crucial for ID estimations when the data lie on a manifold perturbed
        by a high-dimensional noise.
    block_ratio : int, default=20
        Set the minimum size of the blocks as `n_samples/block_ratio`. If ``blockAn=False``, block_ratio is ignored.
    frac : float, default=1
        Define the fraction of points in the data set used for ID calculation. By default the full data set is used.
    n_jobs : int or None, optional (default=None)
        The number of jobs to use for the computation. This works by computing
        each of the n_init runs in parallel.
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`
        for more details.
    affinity : string or callable, default 'precomputed'
        How to construct the affinity matrix.
         - ``nearest_neighbors`` : construct the affinity matrix by computing a
           graph of nearest neighbors.
         - ``rbf`` : construct the affinity matrix using a radial basis function
           (RBF) kernel.
         - ``precomputed`` : interpret ``X`` as a precomputed affinity matrix.
         - ``precomputed_nearest_neighbors`` : interpret ``X`` as a sparse graph
           of precomputed nearest neighbors, and constructs the affinity matrix
           by selecting the ``n_neighbors`` nearest neighbors.
         - one of the kernels supported by
           :func:`~sklearn.metrics.pairwise_kernels`.
    Attributes
    ----------
    dim_ : int
        The intrinsic dimensionality


    References
    ----------

    E. Facco, M. dâ€™Errico, A. Rodriguez and A. Laio, Estimating the intrinsic dimension of datasets by a minimal neighborhood information. `Sci. reports` 7, 12140 (2017)
    """

    def __init__(self, metric='euclidean', blockAn=True, block_ratio=20, frac=1, n_jobs=None,
                 affinity="nearest_neighbors"):
        self.metric = metric
        self.blockAn = blockAn
        self.block_ratio = block_ratio
        self.frac = frac
        self.n_jobs = n_jobs
        self.affinity = affinity

        self.is_fitted_ = False
        self.distances_ = None
        self.indices_ = None
        self.dim_ = None
        self.x_ = None
        self.y_ = None

        if self.frac > 1:
            raise ValueError("frac should be between 0 and 1.")

    def fit(self, X, y=None) -> TwoNearestNeighbors:
        """A reference implementation of a fitting function.
        Parameters
        ----------
        X : array [n_samples, n_samples] if metric == ``precomputed``, or,
            [n_samples, n_features] otherwise
            The input samples. Similarities / affinities between
            instances if ``affinity='precomputed'``.
        y : Ignored
            Not used, present here for API consistency by convention.
        Returns
        -------
        self : object
            Returns self.
        """
        # Input validation
        X = check_array(X, accept_sparse=['csr', 'csc', 'coo'],
                        dtype=np.float64, ensure_min_samples=2)

        allow_squared = self.affinity in ["precomputed",
                                          "precomputed_nearest_neighbors"]
        if X.shape[0] == X.shape[1] and not allow_squared:
            warnings.warn("The twoNN API has changed. ``fit``"
                          "now constructs an affinity matrix from data. To use"
                          " a custom affinity matrix, "
                          "set ``affinity=precomputed``.")

        # if self.block_ratio >= X.shape[0]:
        #     # TOBE implemented
        #     pass
        #     #raise ValueError("block_ratio is larger than the sample size, the minimum size for block analysis \
        #     #           would be zero. Please set a lower value.")

        if self.metric == "precomputed":
            nbrs = NearestNeighbors(n_neighbors=3,
                                    # Only two neighbors used; the point i is counted in its neighborhood
                                    algorithm="brute",
                                    metric=self.metric,
                                    n_jobs=self.n_jobs).fit(X)
        else:
            # Remove duplicates coordinates
            if len(X) > 0:
                X = np.unique(X, axis=0)
            nbrs = NearestNeighbors(n_neighbors=3,
                                    # Only two neighbors used; the point i is counted in its neighborhood
                                    algorithm="auto",
                                    metric=self.metric,
                                    n_jobs=self.n_jobs).fit(X)
        self.distances_, self.indices_ = nbrs.kneighbors(X)

        self.dim_, self.x_, self.y_ = _twoNearestNeighbors(self.distances_,
                                                           blockAn=self.blockAn,
                                                           block_ratio=self.block_ratio,
                                                           frac=self.frac)
        self.is_fitted_ = True
        return self
